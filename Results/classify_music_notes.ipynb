{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kunaual\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\kunaual\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\kunaual\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\kunaual\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\kunaual\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\kunaual\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\kunaual\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\kunaual\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\kunaual\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\kunaual\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\kunaual\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\kunaual\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Sklearn scaling\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sklearn scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# Keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up file and dataframe to store accuracy and loss of modelfit epochs\n",
    "# The code in this cell was commented out after creating the dataframe for all 8 optimizers\n",
    "\n",
    "file = \"modelfit_history.csv\"\n",
    "# modelfit_hist_df = pd.read_csv(file)\n",
    "# modelfit_hist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and process image data using CV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data is found in the kaggle zip file https://www.kaggle.com/kishanj/music-notes-datasets\n",
    "- Zip file was extracted.\n",
    "- All of the image files were in folders for by note type (Whole, Half, Quarter, Eight, Sixteenth)\n",
    "- In order to simplify the code, all files were copied out of their subdirectories into single \"Images\" folder. \n",
    "- The Images folder is part of gitignore, and therefore unavailable from our git repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the Images folder and process each image file\n",
    "# Append the image to a list and append the class name to a separate list\n",
    "\n",
    "img_data_array=[]\n",
    "class_name=[]\n",
    "folder_name = \"Images\"\n",
    "\n",
    "# This code based on https://towardsdatascience.com/loading-custom-image-dataset-for-deep-learning-models-part-1-d64fa7aaeca6\n",
    "# This is the code that required us to install OpenCV2\n",
    "# This code also handles the scaling needed\n",
    "\n",
    "for file in os.listdir(os.path.join(folder_name)):\n",
    "    \n",
    "    image_path= os.path.join(folder_name,  file)\n",
    "    image= cv2.imread( image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    #image=np.array(image)  ????\n",
    "\n",
    "    image = image.astype('float32')\n",
    "    image /= 255 #this gets black and white to 1s and 0s \n",
    "    img_data_array.append(image)\n",
    "    note_class = file[0:1]\n",
    "\n",
    "    class_name.append(note_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(notes_folder):\n",
    "    class_name = []\n",
    "    img_data_array = []\n",
    "    \n",
    "    for note_dir in os.listdir(notes_folder):\n",
    "        \n",
    "        for file in os.listdir(os.path.join(notes_folder, note_dir)):\n",
    "            image = os.path.join(notes_folder, note_dir, file)\n",
    "            image = cv2.imread(notes_folder, cv2.COLOR_BGR2RGB)\n",
    "            #image = cv2.resize( image, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_AREA)\n",
    "            #image = np.array(image)  # converts the image to a numpy array\n",
    "            image = image.astype('float32')\n",
    "            image /= 255\n",
    "            img_data_array.append(image)\n",
    "            class_name.append(note_dir)\n",
    "            \n",
    "    print(img_data_array[0])\n",
    "    return img_data_array, class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e': 0, 'h': 1, 'q': 2, 's': 3, 'w': 4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign a unique number to each class\n",
    "\n",
    "note_classifier_dict = {key:value for value, key in enumerate(np.unique(class_name))}\n",
    "\n",
    "note_classifier_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is y, converting the class names to a numeric value for all values\n",
    "\n",
    "target_val = [note_classifier_dict[class_name[i]] for i in range(len(class_name))]\n",
    "\n",
    "# target_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99607843,\n",
       "        1.        , 0.99607843, 1.        , 0.99607843, 1.        ,\n",
       "        1.        , 0.99215686, 1.        , 0.99607843, 1.        ,\n",
       "        1.        , 0.99607843, 1.        , 0.99607843, 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.99607843, 0.99607843,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99215686, 1.        , 0.9882353 , 1.        , 1.        ,\n",
       "        1.        , 0.9882353 , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99607843,\n",
       "        1.        , 1.        , 0.9843137 , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99215686,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.972549  , 0.5058824 , 0.78039217, 0.99607843, 0.99215686,\n",
       "        0.99215686, 1.        , 0.972549  , 1.        , 1.        ,\n",
       "        1.        , 0.99607843, 1.        , 1.        , 0.9882353 ,\n",
       "        0.99215686, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99215686,\n",
       "        1.        , 0.99215686, 1.        , 0.99607843, 1.        ,\n",
       "        0.9843137 , 0.05098039, 0.26666668, 0.76862746, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99607843,\n",
       "        1.        , 0.99215686, 0.99607843, 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.9882353 , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.99215686, 1.        , 1.        , 1.        ,\n",
       "        0.972549  , 0.        , 0.        , 0.35686275, 0.9607843 ,\n",
       "        1.        , 1.        , 0.99215686, 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.98039216, 1.        , 1.        ,\n",
       "        0.98039216, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99215686, 1.        , 1.        , 1.        , 0.9882353 ,\n",
       "        0.9529412 , 0.01568628, 0.        , 0.02745098, 0.6627451 ,\n",
       "        0.96862745, 0.98039216, 1.        , 0.99607843, 0.99607843,\n",
       "        1.        , 0.99607843, 1.        , 1.        , 0.99215686,\n",
       "        1.        , 1.        , 0.99607843, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99607843, 0.99607843, 1.        ,\n",
       "        0.9647059 , 0.        , 0.10196079, 0.05098039, 0.1254902 ,\n",
       "        0.8392157 , 1.        , 0.98039216, 0.99607843, 0.99607843,\n",
       "        0.9882353 , 0.9882353 , 0.9882353 , 0.99607843, 1.        ,\n",
       "        0.99607843, 0.99607843, 0.99607843, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99215686, 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.92941177, 0.00784314, 0.35686275, 0.3137255 , 0.01176471,\n",
       "        0.39607844, 0.89411765, 1.        , 0.9882353 , 0.99607843,\n",
       "        0.8784314 , 0.8117647 , 0.56078434, 0.7137255 , 0.99215686,\n",
       "        0.99215686, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.99215686, 1.        , 0.99607843, 1.        ,\n",
       "        0.8352941 , 0.00392157, 0.54901963, 0.88235295, 0.10196079,\n",
       "        0.07450981, 0.5764706 , 0.9607843 , 0.9254902 , 0.6784314 ,\n",
       "        0.4392157 , 0.05490196, 0.4117647 , 0.654902  , 0.9607843 ,\n",
       "        1.        , 1.        , 0.99607843, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.99607843, 1.        , 0.99607843, 0.99607843,\n",
       "        0.7254902 , 0.        , 0.68235296, 1.        , 0.7137255 ,\n",
       "        0.17254902, 0.03921569, 0.21568628, 0.29411766, 0.1764706 ,\n",
       "        0.13333334, 0.5647059 , 0.8       , 0.9411765 , 0.99215686,\n",
       "        0.9882353 , 0.9843137 , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99607843,\n",
       "        0.5686275 , 0.00392157, 0.81960785, 0.99215686, 0.9529412 ,\n",
       "        0.57254905, 0.15686275, 0.02352941, 0.05098039, 0.27450982,\n",
       "        0.72156864, 0.9411765 , 1.        , 1.        , 0.99607843,\n",
       "        1.        , 1.        , 0.9882353 , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.43137255, 0.01568628, 0.9490196 , 1.        , 1.        ,\n",
       "        1.        , 0.8627451 , 0.6156863 , 0.58431375, 0.8156863 ,\n",
       "        1.        , 0.98039216, 1.        , 1.        , 0.99607843,\n",
       "        0.99607843, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.99607843, 1.        , 0.99607843, 1.        ,\n",
       "        0.30588236, 0.01568628, 0.9764706 , 0.99215686, 0.99607843,\n",
       "        0.99215686, 0.99607843, 0.94509804, 0.98039216, 0.99607843,\n",
       "        0.99215686, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.99215686, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.99215686, 1.        , 0.99215686, 0.99215686,\n",
       "        0.1764706 , 0.00784314, 0.9764706 , 1.        , 1.        ,\n",
       "        1.        , 0.9843137 , 1.        , 1.        , 0.99215686,\n",
       "        1.        , 0.99607843, 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.99607843, 0.99607843, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99607843, 1.        , 0.99607843, 0.99607843, 0.9843137 ,\n",
       "        0.0627451 , 0.01568628, 0.9843137 , 1.        , 0.99607843,\n",
       "        0.99215686, 1.        , 0.9843137 , 0.99607843, 1.        ,\n",
       "        0.9882353 , 1.        , 0.98039216, 1.        , 0.99607843,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99607843, 1.        , 0.99215686, 1.        , 0.9843137 ,\n",
       "        0.        , 0.02745098, 0.99215686, 0.99215686, 1.        ,\n",
       "        1.        , 0.99607843, 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.99607843, 1.        , 0.99607843, 1.        ,\n",
       "        0.99607843, 0.99607843, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99607843,\n",
       "        0.99607843, 1.        , 1.        , 0.99607843, 0.9764706 ,\n",
       "        0.01568628, 0.01960784, 0.99607843, 0.99607843, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.99607843, 0.9529412 ,\n",
       "        0.00392157, 0.15294118, 0.99607843, 0.99607843, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99607843,\n",
       "        1.        , 0.99607843, 0.99607843, 1.        , 0.95686275,\n",
       "        0.00784314, 0.28627452, 0.99607843, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99215686,\n",
       "        1.        , 0.99607843, 0.99607843, 1.        , 0.93333334,\n",
       "        0.01176471, 0.4117647 , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99607843, 0.99607843, 1.        , 1.        , 0.827451  ,\n",
       "        0.00784314, 0.5568628 , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.99607843, 0.69803923,\n",
       "        0.00784314, 0.68235296, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99607843,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.5686275 ,\n",
       "        0.01568628, 0.81960785, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.99215686, 1.        , 0.99607843, 0.4509804 ,\n",
       "        0.00784314, 0.95686275, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.99607843, 1.        , 0.99215686, 1.        ,\n",
       "        0.99215686, 1.        , 1.        , 1.        , 0.99215686,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.30980393,\n",
       "        0.00784314, 0.96862745, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99607843,\n",
       "        1.        , 0.99607843, 0.99215686, 0.99215686, 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.99607843, 0.16078432,\n",
       "        0.02352941, 0.98039216, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.99215686, 1.        , 0.99607843, 1.        ,\n",
       "        1.        , 0.99215686, 1.        , 1.        , 0.99607843,\n",
       "        0.9882353 , 1.        , 1.        , 0.9843137 , 0.04705882,\n",
       "        0.03137255, 0.9764706 , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.9843137 , 1.        ,\n",
       "        0.9882353 , 0.99607843, 0.99607843, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.96862745, 0.02352941,\n",
       "        0.01568628, 0.98039216, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.99607843, 0.99607843, 1.        , 0.99607843,\n",
       "        1.        , 1.        , 0.9764706 , 1.        , 1.        ,\n",
       "        0.99215686, 0.99215686, 1.        , 0.972549  , 0.01568628,\n",
       "        0.02745098, 0.9882353 , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99215686, 1.        , 1.        ,\n",
       "        0.99215686, 0.98039216, 1.        , 1.        , 0.99607843,\n",
       "        1.        , 0.99607843, 0.99215686, 0.9607843 , 0.        ,\n",
       "        0.14901961, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99607843, 0.99215686, 1.        ,\n",
       "        0.99607843, 1.        , 0.98039216, 0.92941177, 0.9411765 ,\n",
       "        0.9843137 , 0.99607843, 1.        , 0.9490196 , 0.        ,\n",
       "        0.3019608 , 0.99607843, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99607843,\n",
       "        1.        , 0.9764706 , 0.6117647 , 0.5529412 , 0.47058824,\n",
       "        0.56078434, 0.7411765 , 0.95686275, 0.93333334, 0.02352941,\n",
       "        0.40784314, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99215686, 1.        , 1.        ,\n",
       "        0.8862745 , 0.3372549 , 0.14509805, 0.01568628, 0.00784314,\n",
       "        0.11372549, 0.29803923, 0.7176471 , 0.8156863 , 0.        ,\n",
       "        0.5686275 , 0.99607843, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.99215686, 1.        , 1.        , 0.9764706 ,\n",
       "        0.43137255, 0.05098039, 0.        , 0.00392157, 0.01176471,\n",
       "        0.        , 0.01960784, 0.08235294, 0.43137255, 0.00392157,\n",
       "        0.68235296, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.98039216, 1.        , 0.972549  ,\n",
       "        0.09803922, 0.        , 0.00392157, 0.        , 0.        ,\n",
       "        0.00784314, 0.        , 0.        , 0.07058824, 0.00784314,\n",
       "        0.8156863 , 0.99215686, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.9882353 , 0.94509804,\n",
       "        0.03921569, 0.00784314, 0.        , 0.00392157, 0.00392157,\n",
       "        0.01176471, 0.        , 0.        , 0.        , 0.00784314,\n",
       "        0.96862745, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99607843, 1.        , 0.89411765,\n",
       "        0.04313726, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.        , 0.02745098,\n",
       "        0.9764706 , 0.9882353 , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.9882353 , 1.        , 0.96862745,\n",
       "        0.18431373, 0.01176471, 0.00784314, 0.        , 0.01176471,\n",
       "        0.        , 0.        , 0.        , 0.00784314, 0.09019608,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.6392157 , 0.04313726, 0.00784314, 0.        , 0.        ,\n",
       "        0.01568628, 0.00392157, 0.        , 0.        , 0.30980393,\n",
       "        0.9647059 , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99607843, 1.        , 1.        ,\n",
       "        0.91764706, 0.3529412 , 0.03921569, 0.01568628, 0.00392157,\n",
       "        0.        , 0.        , 0.00392157, 0.03137255, 0.6745098 ,\n",
       "        1.        , 0.99215686, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.99607843, 1.        ,\n",
       "        0.9882353 , 0.8862745 , 0.32941177, 0.02745098, 0.00392157,\n",
       "        0.00392157, 0.00784314, 0.01568628, 0.34509805, 0.98039216,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99215686, 1.        , 1.        ,\n",
       "        0.99607843, 1.        , 0.9529412 , 0.6392157 , 0.35686275,\n",
       "        0.1764706 , 0.14117648, 0.4627451 , 0.8235294 , 0.99607843,\n",
       "        0.9882353 , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.9882353 ,\n",
       "        1.        , 1.        , 0.99607843, 0.9607843 , 0.88235295,\n",
       "        0.8666667 , 0.84705883, 0.92156863, 1.        , 0.99607843,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.9882353 , 1.        , 1.        ,\n",
       "        0.99607843, 1.        , 0.99607843, 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.9882353 , 0.9843137 , 1.        ,\n",
       "        0.99215686, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.99607843, 1.        , 0.99215686, 0.9843137 ,\n",
       "        1.        , 0.99215686, 1.        , 0.99607843, 0.99607843,\n",
       "        1.        , 0.99607843, 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.99607843, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99215686, 1.        , 0.99607843,\n",
       "        1.        , 0.99607843, 0.99607843, 1.        , 1.        ,\n",
       "        0.99215686, 1.        , 0.99215686, 1.        , 0.99607843,\n",
       "        1.        , 0.99607843, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.99215686, 1.        , 1.        , 1.        ,\n",
       "        0.99607843, 0.99607843, 1.        , 0.99607843, 1.        ,\n",
       "        0.99215686, 1.        , 0.99215686, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99215686, 0.99607843, 0.99607843,\n",
       "        1.        , 0.99215686, 0.99607843, 1.        , 1.        ,\n",
       "        0.99607843, 0.99607843, 1.        , 1.        , 0.99607843,\n",
       "        1.        , 0.99607843, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the image array ... setting the threshold to 4096 or above avoids truncating the array\n",
    "\n",
    "np.set_printoptions(threshold=4096)\n",
    "\n",
    "img_data_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19dbb3e99b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test to make sure our images are still good\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img_data_array[10], cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the 64x64 pixels to 1D array \n",
    "# This is similar to what was done in MNIST class example\n",
    "\n",
    "num_dimensions = 64*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make this an np array so we can use reshape on our array to flatten\n",
    "# the array from 64 x 64 to 1 x 4096 (from a vector matrix to a scalar matrix)\n",
    "\n",
    "x=np.array(img_data_array, np.float32)\n",
    "\n",
    "reshape_test = x.reshape(x.shape[0],num_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 4096)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reshape_test,target_val, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *NOTE*:  Instead of using the code in this cell, we performed the scaling manually above \n",
    "# using 'image /= 255' as we loaded each image \n",
    "\n",
    "# Next, we normalize our training data to be between 0 and 1\n",
    "# scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 3, 0, 0, 1, 4, 4, 2, 4, 0, 2, 2, 1, 1, 1, 1, 3, 1, 4, 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our Training and Testing labels are integer encoded from 0 to 4\n",
    "y_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have five categories: whole, half, quarter, eighth, and sixteenth notes\n",
    "num_classes = 5\n",
    "\n",
    "# Encode the target using one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first layer where the input dimensions are 4096 pixels\n",
    "# Activation function using 'relu' for the hidden layers and 'softmax' for the output layer\n",
    "# Each of the hidden layers are densely connected and have 100 nodes per layer\n",
    "model.add(Dense(100, activation='relu', input_dim=X_train.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a second hidden layer with 100 densely connected nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(100, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final output layer uses softmax activation function for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 100)               409700    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 420,305\n",
      "Trainable params: 420,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and Train our Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These were run one at a time, with only one optimizer in play for each run\n",
    "All of the optimizers were run.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  optimizer = \"Adam\"\n",
    "# optimizer = \"SGD\"\n",
    "# optimizer = \"RMSprop\"\n",
    "# optimizer = \"Adadelta\"\n",
    "# optimizer = \"Adagrad\"\n",
    "# optimizer = \"Adamax\"\n",
    "# optimizer = \"Nadam\"\n",
    "optimizer = tf.keras.optimizers.Ftrl(learning_rate=.001)#1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train (fit) our model using the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are setting the model.fit() equal to a variable 'history' in order to use it to create the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below 3 cells were just to store model fit timings to dataframe. commented out after timings achieved.\n",
    "# import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# history = model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     epochs=100,\n",
    "#     shuffle=True,\n",
    "#     verbose=0\n",
    "#     )\n",
    "# end = time.time()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timer_list = []\n",
    "# timer_list.append([optimizer, round(end - start,2)])\n",
    "# timer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timer_df=pd.DataFrame(timer_list,columns=[\"Optimizer\",\"Model_Fit_Time\"])\n",
    "# timer_df.to_csv('Model_fit_100Epoch_timer.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a dataframe to hold the model fit history values\n",
    "# modelfit_hist_df=pd.DataFrame()   #only needed for first run\n",
    "modelfit_hist_df[\"ftrl_loss\"] = history.history['loss']  #only needed for last one\n",
    "modelfit_hist_df[\"ftrl_acc\"] = history.history['acc']   #only needed for last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelfit_hist_df[optimizer+\"_loss\"] = history.history['loss']\n",
    "# modelfit_hist_df[optimizer+\"_acc\"] = history.history['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adam_loss</th>\n",
       "      <th>Adam_acc</th>\n",
       "      <th>SGD_loss</th>\n",
       "      <th>SGD_acc</th>\n",
       "      <th>RMSprop_loss</th>\n",
       "      <th>RMSprop_acc</th>\n",
       "      <th>Adadelta_loss</th>\n",
       "      <th>Adadelta_acc</th>\n",
       "      <th>Adagrad_loss</th>\n",
       "      <th>Adagrad_acc</th>\n",
       "      <th>Adamax_loss</th>\n",
       "      <th>Adamax_acc</th>\n",
       "      <th>Nadam_loss</th>\n",
       "      <th>Nadam_acc</th>\n",
       "      <th>ftrl_loss</th>\n",
       "      <th>ftrl_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.423147</td>\n",
       "      <td>0.398400</td>\n",
       "      <td>1.521942</td>\n",
       "      <td>0.325333</td>\n",
       "      <td>2.277595</td>\n",
       "      <td>0.264267</td>\n",
       "      <td>1.803276</td>\n",
       "      <td>0.197067</td>\n",
       "      <td>1.524281</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>1.383007</td>\n",
       "      <td>0.400800</td>\n",
       "      <td>1.639992</td>\n",
       "      <td>0.337067</td>\n",
       "      <td>1.612974</td>\n",
       "      <td>0.191200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.975080</td>\n",
       "      <td>0.600800</td>\n",
       "      <td>1.326020</td>\n",
       "      <td>0.412533</td>\n",
       "      <td>1.470545</td>\n",
       "      <td>0.376800</td>\n",
       "      <td>1.635225</td>\n",
       "      <td>0.193867</td>\n",
       "      <td>1.248959</td>\n",
       "      <td>0.498400</td>\n",
       "      <td>1.072190</td>\n",
       "      <td>0.572800</td>\n",
       "      <td>1.194547</td>\n",
       "      <td>0.486133</td>\n",
       "      <td>1.609431</td>\n",
       "      <td>0.202667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.838830</td>\n",
       "      <td>0.656267</td>\n",
       "      <td>1.229770</td>\n",
       "      <td>0.461867</td>\n",
       "      <td>1.279867</td>\n",
       "      <td>0.435733</td>\n",
       "      <td>1.582964</td>\n",
       "      <td>0.236533</td>\n",
       "      <td>1.150473</td>\n",
       "      <td>0.578400</td>\n",
       "      <td>0.932655</td>\n",
       "      <td>0.631467</td>\n",
       "      <td>1.098583</td>\n",
       "      <td>0.551467</td>\n",
       "      <td>1.609407</td>\n",
       "      <td>0.203733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.721202</td>\n",
       "      <td>0.694667</td>\n",
       "      <td>1.121811</td>\n",
       "      <td>0.510667</td>\n",
       "      <td>1.232945</td>\n",
       "      <td>0.478667</td>\n",
       "      <td>1.556724</td>\n",
       "      <td>0.281333</td>\n",
       "      <td>1.082773</td>\n",
       "      <td>0.612800</td>\n",
       "      <td>0.882641</td>\n",
       "      <td>0.637333</td>\n",
       "      <td>0.959175</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>1.609385</td>\n",
       "      <td>0.203733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.684502</td>\n",
       "      <td>0.713067</td>\n",
       "      <td>1.122801</td>\n",
       "      <td>0.529867</td>\n",
       "      <td>1.123271</td>\n",
       "      <td>0.536800</td>\n",
       "      <td>1.538437</td>\n",
       "      <td>0.331733</td>\n",
       "      <td>1.029100</td>\n",
       "      <td>0.629067</td>\n",
       "      <td>0.777351</td>\n",
       "      <td>0.688800</td>\n",
       "      <td>0.881424</td>\n",
       "      <td>0.620533</td>\n",
       "      <td>1.609361</td>\n",
       "      <td>0.203733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.106645</td>\n",
       "      <td>0.960533</td>\n",
       "      <td>0.261468</td>\n",
       "      <td>0.921600</td>\n",
       "      <td>0.207965</td>\n",
       "      <td>0.941867</td>\n",
       "      <td>1.012725</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.409327</td>\n",
       "      <td>0.866133</td>\n",
       "      <td>0.088129</td>\n",
       "      <td>0.971733</td>\n",
       "      <td>0.034892</td>\n",
       "      <td>0.989867</td>\n",
       "      <td>1.124863</td>\n",
       "      <td>0.522133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.143877</td>\n",
       "      <td>0.948267</td>\n",
       "      <td>0.139401</td>\n",
       "      <td>0.951467</td>\n",
       "      <td>0.184590</td>\n",
       "      <td>0.944267</td>\n",
       "      <td>1.009720</td>\n",
       "      <td>0.666133</td>\n",
       "      <td>0.408460</td>\n",
       "      <td>0.861600</td>\n",
       "      <td>0.067114</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.072421</td>\n",
       "      <td>0.975467</td>\n",
       "      <td>1.120839</td>\n",
       "      <td>0.521067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.049912</td>\n",
       "      <td>0.981067</td>\n",
       "      <td>0.183360</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.222012</td>\n",
       "      <td>0.938667</td>\n",
       "      <td>1.007210</td>\n",
       "      <td>0.665067</td>\n",
       "      <td>0.406451</td>\n",
       "      <td>0.865600</td>\n",
       "      <td>0.095791</td>\n",
       "      <td>0.964533</td>\n",
       "      <td>0.086361</td>\n",
       "      <td>0.978400</td>\n",
       "      <td>1.116178</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.076292</td>\n",
       "      <td>0.972533</td>\n",
       "      <td>0.148199</td>\n",
       "      <td>0.954933</td>\n",
       "      <td>0.165674</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>1.004020</td>\n",
       "      <td>0.667733</td>\n",
       "      <td>0.405772</td>\n",
       "      <td>0.864533</td>\n",
       "      <td>0.072626</td>\n",
       "      <td>0.977067</td>\n",
       "      <td>0.032087</td>\n",
       "      <td>0.992267</td>\n",
       "      <td>1.112328</td>\n",
       "      <td>0.524267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.066959</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.195240</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.213782</td>\n",
       "      <td>0.941600</td>\n",
       "      <td>1.001245</td>\n",
       "      <td>0.669333</td>\n",
       "      <td>0.405249</td>\n",
       "      <td>0.866933</td>\n",
       "      <td>0.068006</td>\n",
       "      <td>0.979200</td>\n",
       "      <td>0.046853</td>\n",
       "      <td>0.987733</td>\n",
       "      <td>1.108758</td>\n",
       "      <td>0.523467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Adam_loss  Adam_acc  SGD_loss   SGD_acc  RMSprop_loss  RMSprop_acc  \\\n",
       "0    1.423147  0.398400  1.521942  0.325333      2.277595     0.264267   \n",
       "1    0.975080  0.600800  1.326020  0.412533      1.470545     0.376800   \n",
       "2    0.838830  0.656267  1.229770  0.461867      1.279867     0.435733   \n",
       "3    0.721202  0.694667  1.121811  0.510667      1.232945     0.478667   \n",
       "4    0.684502  0.713067  1.122801  0.529867      1.123271     0.536800   \n",
       "..        ...       ...       ...       ...           ...          ...   \n",
       "95   0.106645  0.960533  0.261468  0.921600      0.207965     0.941867   \n",
       "96   0.143877  0.948267  0.139401  0.951467      0.184590     0.944267   \n",
       "97   0.049912  0.981067  0.183360  0.940000      0.222012     0.938667   \n",
       "98   0.076292  0.972533  0.148199  0.954933      0.165674     0.944000   \n",
       "99   0.066959  0.973333  0.195240  0.940000      0.213782     0.941600   \n",
       "\n",
       "    Adadelta_loss  Adadelta_acc  Adagrad_loss  Adagrad_acc  Adamax_loss  \\\n",
       "0        1.803276      0.197067      1.524281     0.363733     1.383007   \n",
       "1        1.635225      0.193867      1.248959     0.498400     1.072190   \n",
       "2        1.582964      0.236533      1.150473     0.578400     0.932655   \n",
       "3        1.556724      0.281333      1.082773     0.612800     0.882641   \n",
       "4        1.538437      0.331733      1.029100     0.629067     0.777351   \n",
       "..            ...           ...           ...          ...          ...   \n",
       "95       1.012725      0.666667      0.409327     0.866133     0.088129   \n",
       "96       1.009720      0.666133      0.408460     0.861600     0.067114   \n",
       "97       1.007210      0.665067      0.406451     0.865600     0.095791   \n",
       "98       1.004020      0.667733      0.405772     0.864533     0.072626   \n",
       "99       1.001245      0.669333      0.405249     0.866933     0.068006   \n",
       "\n",
       "    Adamax_acc  Nadam_loss  Nadam_acc  ftrl_loss  ftrl_acc  \n",
       "0     0.400800    1.639992   0.337067   1.612974  0.191200  \n",
       "1     0.572800    1.194547   0.486133   1.609431  0.202667  \n",
       "2     0.631467    1.098583   0.551467   1.609407  0.203733  \n",
       "3     0.637333    0.959175   0.608000   1.609385  0.203733  \n",
       "4     0.688800    0.881424   0.620533   1.609361  0.203733  \n",
       "..         ...         ...        ...        ...       ...  \n",
       "95    0.971733    0.034892   0.989867   1.124863  0.522133  \n",
       "96    0.980000    0.072421   0.975467   1.120839  0.521067  \n",
       "97    0.964533    0.086361   0.978400   1.116178  0.520000  \n",
       "98    0.977067    0.032087   0.992267   1.112328  0.524267  \n",
       "99    0.979200    0.046853   0.987733   1.108758  0.523467  \n",
       "\n",
       "[100 rows x 16 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelfit_hist_df #test output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfit_hist_df.to_csv(file, index=False)\n",
    "#modelfit_hist_df.to_csv('FTRL_ACC_LOSS.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history.model #testing output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the Optimizer performance\n",
    "The loss and accuracy for each optimizer and save each plot as a file and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kunaual\\anaconda3\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:8: MatplotlibDeprecationWarning: Unrecognized location 'middle'. Falling back on 'best'; valid locations are\n",
      "\tbest\n",
      "\tupper right\n",
      "\tupper left\n",
      "\tlower left\n",
      "\tlower right\n",
      "\tright\n",
      "\tcenter left\n",
      "\tcenter right\n",
      "\tlower center\n",
      "\tupper center\n",
      "\tcenter\n",
      "This will raise an exception in 3.3.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Loss (training data)')\n",
    "# plt.plot(history.history['acc'], label='MAE (validation data)')\n",
    "plt.plot(history.history['acc'], label='Accuracy (training data)')\n",
    "# plt.title('Loss and Accuracy vs. Epochs - Optimizer: '+ optimizer)\n",
    "plt.title('Loss and Accuracy vs. Epochs - Optimizer: FTRL')\n",
    "plt.ylabel('Model Efficiency')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"middle\")\n",
    "# plt.savefig(\"Results/100epoch_relu_\" + optimizer + \".jpeg\")\n",
    "plt.savefig(\"Results/100epoch_relu_FTRL.jpeg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented out so we don't resave over existing file\n",
    "model.save(\"Results/Notes_relu_\" + optimizer + \".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "Evaluate each of the 8 optimizers and store the loss and accuracy in a new DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define list to hold model eval results\n",
    "# df_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this box was used for ftrl alone as it's not save-able via standard save command.  it was run *after all the function below was run\n",
    "# model_loss, model_accuracy = model.evaluate(X_test,y_test, verbose=2)\n",
    "df_list.append(['ftrl', model_loss,model_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predictions(results_folder):\n",
    "\n",
    "    \n",
    "     for model_file in os.listdir(os.path.join(results_folder)):\n",
    "            if \"h5\" in model_file:\n",
    "                print(\"working on file: \"+model_file)\n",
    "                model = load_model(os.path.join(results_folder,model_file))\n",
    "#                 break #for testing purposes only\n",
    "                try:\n",
    "                    model_loss, model_accuracy = model.evaluate(X_test,y_test, verbose=2)\n",
    "                    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "                    df_list.append([model_file, model_loss,model_accuracy])\n",
    "                except:\n",
    "                    print(\"Ftrl model defies being saved and will not load. filename:\"+model_file)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on file: notes_relu_Adadelta.h5\n",
      "WARNING:tensorflow:From C:\\Users\\kunaual\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\kunaual\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "1250/1250 - 0s - loss: 1.0089 - acc: 0.6488\n",
      "Loss: 1.0088697247982026, Accuracy: 0.6488000154495239\n",
      "working on file: notes_relu_Adagrad.h5\n",
      "1250/1250 - 0s - loss: 0.4594 - acc: 0.8424\n",
      "Loss: 0.4593663999140263, Accuracy: 0.8424000144004822\n",
      "working on file: notes_relu_Adam.h5\n",
      "1250/1250 - 0s - loss: 0.1324 - acc: 0.9600\n",
      "Loss: 0.1324001303553563, Accuracy: 0.9599999785423279\n",
      "working on file: notes_relu_Adamax.h5\n",
      "1250/1250 - 0s - loss: 0.1591 - acc: 0.9504\n",
      "Loss: 0.15908841733931914, Accuracy: 0.9503999948501587\n",
      "working on file: notes_relu_Ftrl.h5\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Ftrl model defies being saved and will not load. filename:notes_relu_Ftrl.h5\n",
      "working on file: notes_relu_Nadam.h5\n",
      "1250/1250 - 0s - loss: 0.1940 - acc: 0.9408\n",
      "Loss: 0.19397523674964906, Accuracy: 0.9408000111579895\n",
      "working on file: notes_relu_RMSprop.h5\n",
      "1250/1250 - 0s - loss: 0.9425 - acc: 0.7600\n",
      "Loss: 0.9425227928161621, Accuracy: 0.7599999904632568\n",
      "working on file: notes_relu_SGD.h5\n",
      "1250/1250 - 0s - loss: 0.1545 - acc: 0.9480\n",
      "Loss: 0.15445830640678176, Accuracy: 0.9480000138282776\n"
     ]
    }
   ],
   "source": [
    "model_predictions('Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['notes_relu_Adadelta.h5', 1.0088697247982026, 0.6488], ['notes_relu_Adagrad.h5', 0.4593663999140263, 0.8424], ['notes_relu_Adam.h5', 0.1324001303553563, 0.96], ['notes_relu_Adamax.h5', 0.15908841733931914, 0.9504], ['notes_relu_Nadam.h5', 0.19397523674964906, 0.9408], ['notes_relu_RMSprop.h5', 0.9425227928161621, 0.76], ['notes_relu_SGD.h5', 0.15445830640678176, 0.948], ['ftrl', 1.108062178325653, 0.5416]]\n"
     ]
    }
   ],
   "source": [
    "# put results to df\n",
    "print(df_list)\n",
    "results_df = pd.DataFrame(df_list,columns=[\"Model\",\"Loss\",\"Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv for later loading/graphing elsewhere\n",
    "results_df.to_csv(os.path.join('Results','Model_predict_loss_acc.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>notes_relu_Adadelta.h5</td>\n",
       "      <td>1.008870</td>\n",
       "      <td>0.6488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>notes_relu_Adagrad.h5</td>\n",
       "      <td>0.459366</td>\n",
       "      <td>0.8424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>notes_relu_Adam.h5</td>\n",
       "      <td>0.132400</td>\n",
       "      <td>0.9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>notes_relu_Adamax.h5</td>\n",
       "      <td>0.159088</td>\n",
       "      <td>0.9504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notes_relu_Nadam.h5</td>\n",
       "      <td>0.193975</td>\n",
       "      <td>0.9408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>notes_relu_RMSprop.h5</td>\n",
       "      <td>0.942523</td>\n",
       "      <td>0.7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>notes_relu_SGD.h5</td>\n",
       "      <td>0.154458</td>\n",
       "      <td>0.9480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ftrl</td>\n",
       "      <td>1.108062</td>\n",
       "      <td>0.5416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model      Loss  Accuracy\n",
       "0  notes_relu_Adadelta.h5  1.008870    0.6488\n",
       "1   notes_relu_Adagrad.h5  0.459366    0.8424\n",
       "2      notes_relu_Adam.h5  0.132400    0.9600\n",
       "3    notes_relu_Adamax.h5  0.159088    0.9504\n",
       "4     notes_relu_Nadam.h5  0.193975    0.9408\n",
       "5   notes_relu_RMSprop.h5  0.942523    0.7600\n",
       "6       notes_relu_SGD.h5  0.154458    0.9480\n",
       "7                    ftrl  1.108062    0.5416"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try our model on some hand drawn notes\n",
    "shout out to MS Paint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(os.path.join('Results','notes_relu_Adam.h5'))  # change file for the model you want to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put a file in the TestImage folder and set it to filepath here.  Note we've tested a few different files already:\n",
    "#filepath = \"TestImage/note_pensketch.jpg\"   # so it thought this guy was an eigth note\n",
    "#filepath = \"TestImage/mn5.png\"  # successfully predicted Fukhrudin's whole notes\n",
    "#filepath = \"TestImage/sharon.png\"  \n",
    "filepath = \"TestImage/eigth_fukhrudin.png\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "image_size = (64, 64)\n",
    "im = image.load_img(filepath, target_size=image_size, color_mode=\"grayscale\")\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to a numpy array \n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image = img_to_array(im)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the image pixels by 255 (or use a scaler from sklearn here)\n",
    "image /= 255\n",
    "\n",
    "# Flatten into a 1x28*28 array \n",
    "img = image.flatten().reshape(-1, 64*64)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img.reshape(64, 64), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dictionary of classifications\n",
    "{'eigth': 0, 'half': 1, 'quarter': 2, 'sixteenth': 3, 'whole': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
